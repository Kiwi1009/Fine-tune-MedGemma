# 🚀 MedGemma 27B 中文微調 - 快速開始指南

## 📋 前置需求

### 硬體需求
- **GPU**: NVIDIA GPU，至少 24GB VRAM (推薦 RTX 4090)
- **記憶體**: 至少 32GB 系統記憶體
- **儲存**: 至少 50GB 可用空間

### 軟體需求
- **Python**: 3.8 或更高版本
- **CUDA**: 11.8 或更高版本

## ⚡ 快速安裝

### 1. 克隆專案
```bash
git clone https://github.com/your-username/Fine-tune-MedGemma.git
cd Fine-tune-MedGemma
```

### 2. 創建虛擬環境
```bash
# 使用 conda
conda create -n medgemma python=3.10
conda activate medgemma

# 或使用 venv
python -m venv medgemma_env
source medgemma_env/bin/activate  # Linux/Mac
# 或
medgemma_env\Scripts\activate  # Windows
```

### 3. 安裝依賴
```bash
pip install -r requirements.txt
```

### 4. 安裝 PyTorch (根據您的 CUDA 版本)
```bash
# CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## 🔐 模型存取設置

### 1. 申請 MedGemma 存取權限
1. 前往 [MedGemma 模型頁面](https://huggingface.co/google/medgemma-27b-multimodal)
2. 點擊 "Request Access"
3. 接受授權協議
4. 等待審核通過

### 2. 取得 HuggingFace Token
1. 前往 [Token 設置頁面](https://huggingface.co/settings/tokens)
2. 點擊 "New token"
3. 選擇 "Read" 權限
4. 複製生成的 token

### 3. 設置環境變數
```bash
# Linux/Mac
export HUGGINGFACE_HUB_TOKEN="your_token_here"

# Windows
set HUGGINGFACE_HUB_TOKEN=your_token_here
```

## 📊 數據準備

### 1. 準備 MedQuAD 數據集
確保 `medquad.csv` 文件在專案目錄中，包含以下欄位：
- `question`: 醫療問題
- `answer`: 醫療回答
- `source`: 數據來源
- `focus_area`: 專注領域

### 2. 數據格式範例
```csv
question,answer,source,focus_area
"什麼是糖尿病?","糖尿病是一種代謝疾病...",medical_textbook,endocrinology
"高血壓的症狀有哪些?","高血壓的症狀包括...",medical_textbook,cardiology
```

## 🚀 開始訓練

### 方法 1: 使用 Jupyter Notebook
```bash
jupyter notebook finetune_medgemma_27b_中文.ipynb
```

### 方法 2: 使用 Python 腳本
```bash
# 使用默認配置
python train_medgemma_27b.py

# 使用自定義配置
python train_medgemma_27b.py --config config.json

# 調整參數
python train_medgemma_27b.py --batch_size 2 --sample_size 1000 --num_epochs 2
```

### 方法 3: 使用配置文件
```bash
# 編輯 config.json 調整參數
python train_medgemma_27b.py --config config.json
```

## 📈 監控訓練

### 1. GPU 記憶體監控
```bash
nvidia-smi -l 1
```

### 2. TensorBoard 監控
```bash
tensorboard --logdir ./results
```

### 3. 訓練日誌
訓練日誌保存在 `./results/` 目錄中

## 🧪 測試模型

### 1. 載入微調模型
```python
from peft import PeftModel
from transformers import AutoModelForCausalLM, AutoTokenizer

# 載入基礎模型
base_model = AutoModelForCausalLM.from_pretrained("google/medgemma-27b-multimodal")
tokenizer = AutoTokenizer.from_pretrained("google/medgemma-27b-multimodal")

# 載入 LoRA 適配器
finetuned_model = PeftModel.from_pretrained(base_model, "./finetuned_medgemma_27b")
```

### 2. 生成醫療回答
```python
def generate_medical_response(question):
    test_input = f"Instruction: {question}\nResponse:"
    inputs = tokenizer(test_input, return_tensors="pt")
    
    with torch.no_grad():
        outputs = finetuned_model.generate(
            **inputs,
            max_new_tokens=256,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.split("Response:")[-1].strip()

# 測試
question = "糖尿病的症狀是什麼?"
answer = generate_medical_response(question)
print(f"問題: {question}")
print(f"回答: {answer}")
```

## 🔧 常見問題

### 1. CUDA 記憶體不足
**解決方案**:
- 減少 `batch_size` (從 4 改為 2)
- 減少 `max_length` (從 512 改為 256)
- 增加 `gradient_accumulation_steps` (從 4 改為 8)

### 2. 模型存取被拒絕
**解決方案**:
- 確認已申請 MedGemma 模型存取權限
- 檢查 HuggingFace token 是否正確
- 重新執行認證

### 3. 套件版本衝突
**解決方案**:
- 使用虛擬環境
- 更新到指定版本: `pip install transformers==4.44.0`
- 重新安裝衝突套件

## 📊 性能基準

| GPU 型號 | VRAM | 批次大小 | 序列長度 | 訓練時間 |
|----------|------|----------|----------|----------|
| RTX 4090 | 24GB | 4 | 512 | ~2小時 |
| RTX 3090 | 24GB | 2 | 512 | ~4小時 |
| RTX 3080 | 10GB | 1 | 256 | ~8小時 |

## ⚠️ 重要提醒

- **醫療免責聲明**: 此模型僅供教育和研究用途
- **數據隱私**: 確保使用適當的醫療數據
- **模型限制**: 可能存在偏見和不準確性

## 📞 支援

如果遇到問題：
1. 查看 `README_中文.md` 的詳細說明
2. 檢查故障排除部分
3. 創建 Issue 並提供詳細資訊

---

**祝您訓練順利！** 🚀 